{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping VI Tutorial\n",
    "\n",
    "As an example, we demonstrate the use of our Early Stopping VI methodology on the following simple linear system used in LazyVI (Gao et al. 2022):\n",
    "\n",
    "$$f(x) = 1.5x_1 + 1.2x_2 + x_3 + \\epsilon$$\n",
    "\n",
    "Where $\\epsilon \\sim N(0,0.1)$ and $X \\sim N(0, \\Sigma_{6 \\times 6})$, so the response only depends on the first three of the six variables. All variables are independent except for $x_1$ and $x_2$, whose correlation is $\\rho$.  \n",
    "\n",
    "We drop $x_1$. And the true VI under negative MSE is $VI_1 = (1.5)^2(1-\\rho^2)$. We show how to apply our proposed early stopping warm-start framework using \n",
    "neural network and GBDT to estimate $VI_1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nn_utils import *\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from itertools import chain, combinations\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.5\n",
    "beta = np.array([1.5, 1.2, 1, 0, 0, 0])\n",
    "X, Y = generate_linear_data(beta=beta, sigma= 0.1, corr=rho)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drop_i = 0\n",
    "\n",
    "m = 128\n",
    "\n",
    "p = beta.shape[0]\n",
    "\n",
    "widths = [p,m,1]\n",
    "\n",
    "X_fit, X_test, y_fit, y_test = train_test_split(X, Y,random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_fit, y_fit,random_state=1)\n",
    "X_fit_drop = X_fit.clone()\n",
    "X_fit_drop[:,drop_i] = torch.mean(X_fit_drop[:,drop_i])\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "dm = FlexDataModule( X_train, y_train, X_val, y_val)\n",
    "\n",
    "\n",
    "#train full model\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "full_nn = LazyNet(widths,lr = lr)\n",
    "full_nn.reset_parameters()\n",
    "early_stopping = EarlyStopping('val_loss', min_delta=1e-3)\n",
    "cb = MetricTracker()\n",
    "trainer = pl.Trainer(callbacks=[cb,early_stopping], max_epochs=800,enable_progress_bar=False,enable_model_summary=False)\n",
    "trainer.fit(full_nn, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train early stopping network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropS = [0]\n",
    "X_train_drop, X_val_drop, X_test_drop = dropdata(X_train,X_val, X_test,dropS)\n",
    "lazy_nn = LazyNet(widths,lr = 0.1)\n",
    "lazy_nn.init_parameters(full_nn)\n",
    "\n",
    "\n",
    "dm_lazy = FlexDataModule( X_train_drop, y_train,  X_val_drop,  y_val)\n",
    "early_stopping = EarlyStopping('val_loss', min_delta=1e-3)\n",
    "cb = MetricTracker()\n",
    "\n",
    "trainer = pl.Trainer(callbacks=[cb,early_stopping], max_epochs=100,enable_progress_bar=False,enable_model_summary=False)\n",
    "trainer.fit(lazy_nn, dm_lazy)\n",
    "print(trainer.current_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es nn vi  1.6991448402404785\n",
      "drop nn vi 2.2758593559265137\n",
      "true vi 1.6875\n"
     ]
    }
   ],
   "source": [
    "vi_est = torch.mean((lazy_nn(X_test_drop) - y_test)**2)  -  torch.mean((full_nn(X_test) - y_test)**2) \n",
    "vi_drop =  torch.mean((full_nn(X_test_drop) - y_test)**2)  -  torch.mean((full_nn(X_test) - y_test)**2) \n",
    "print('es nn vi ',vi_est.item())\n",
    "print('drop nn vi',vi_drop.item())\n",
    "print('true vi', 1.5**2*(1-rho**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_gdbt import *\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from itertools import chain, combinations\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho  = 0.5\n",
    "beta = np.array([1.5, 1.2, 1, 0, 0, 0])\n",
    "X, Y = generate_linear_data(beta=beta, sigma= 0.1, corr=rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train full GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_i = 0 \n",
    "\n",
    "X_fit, X_test, y_fit, y_test = train_test_split(X, Y,random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_fit, y_fit,random_state=1)\n",
    "X_fit_drop = np.copy(X_fit)\n",
    "X_fit_drop[:,drop_i] = np.mean(X_fit_drop[:,drop_i])\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "depth = 3\n",
    "lr = 0.1\n",
    "es_lr = 0.1\n",
    "plot = False\n",
    "\n",
    "\n",
    "\n",
    "train_pool = Pool(X_train,y_train)\n",
    "model_full= CatBoostRegressor(iterations=max_iter,\n",
    "                            depth= depth,\n",
    "                            learning_rate= lr,\n",
    "                            random_strength= 10000,\n",
    "                            loss_function='RMSE',\n",
    "                            verbose=False,\n",
    "                            seed = 1,\n",
    "                            feature_border_type='Median',\n",
    "                            score_function='L2',            \n",
    "                            )\n",
    "model_full.fit(train_pool,eval_set=(X_val, y_val), early_stopping_rounds = 10,plot = plot)\n",
    "pre_full = np.mean((model_full.predict(X_test) - y_test)**2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train early stopping GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f8f2234e4f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropS = [0]\n",
    "\n",
    "X_train_drop, X_val_drop, X_test_drop = dropdata(X_train,X_val, X_test,dropS)\n",
    "\n",
    "vi_drop = np.mean((model_full.predict(X_test_drop) - y_test)**2) - pre_full\n",
    "\n",
    "\n",
    "train_pool_red = Pool(X_train_drop,y_train)\n",
    "\n",
    "model_es= CatBoostRegressor(iterations=max_iter,\n",
    "                                            depth= depth,\n",
    "                                            learning_rate= es_lr,\n",
    "                                            random_strength= 10000,\n",
    "                                            loss_function='RMSE',\n",
    "                                            verbose=False,\n",
    "                                            feature_border_type='Median',\n",
    "                                            score_function='L2'\n",
    "                                            )\n",
    "            \n",
    "model_es.fit(train_pool_red,eval_set=(X_val_drop, y_val), init_model= model_full,   early_stopping_rounds = 10,plot = plot)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es GBDT vi  1.6533495699790286\n",
      "drop GBDT vi 2.0786511029884336\n",
      "true vi 1.6875\n"
     ]
    }
   ],
   "source": [
    "vi_est =  np.mean((model_es.predict(X_test_drop) - y_test)**2) - pre_full\n",
    "print('es GBDT vi ',vi_est)\n",
    "print('drop GBDT vi',vi_drop)\n",
    "print('true vi', 1.5**2*(1-rho**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
